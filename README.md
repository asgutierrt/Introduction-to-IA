# Multi-Layer Perceptron (MLP) [![](https://img.shields.io/badge/pdf-EF3939?style=flat&logo=adobeacrobatreader&logoColor=white)](neural_networks/mlp_data/mlp_results/on_neural_networks_training.pdf)

Learning exercise about the training of a multilayer perceptron (MLP), a type of artificial neural network. It also encompasses the development of criteria to confidently make deductions about the training process and characteristics. The methodology called gradient descent looks to minimize errors in the modeled output in an iterative way. Additionally, we correlate the results to the learning problem that motivates the use of a MLP model. The work is based on non-standard data provided as part of our course, giving us a chance to put our theoretical knowledge into practice.

# Hybrid Applications [![](https://img.shields.io/badge/pdf-EF3939?style=flat&logo=adobeacrobatreader&logoColor=white)](https://github.com/asgutierrt/Introduction-to-IA/blob/d63b0d4b1ad57edb165c2247fa9faa3ac5ee20c8/convolutional_networks/on_autoencoder_cnn_gan_training.pdf)

This section explores the use of NN in classification, regression, and feature extraction. It implements autoencoders to manipulate data dimensionality and assess their
impact on regression tasks. The CNN LeNET5â€™s application for MNIST dataset classification, and a validation on dataset created in the classroom. Additionally, Generative Adversarial Networks (GANs) are used for their generative and discriminative modeling, once again validated using the classroom digits dataset. One last network, Style-GAN, explores image generation and modification. 

\* Autoencoders and Convolutional Neural Networks (LeNet5) \* Generative adversarial networks and style transfer
