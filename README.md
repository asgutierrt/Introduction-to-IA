# Multi-Layer perceptron (MLP) [![](https://img.shields.io/badge/pdf-EF3939?style=flat&logo=adobeacrobatreader&logoColor=white)](neural_networks/mlp_data/mlp_results/on_neural_networks_training.pdf)

Learning exercise about the training of a multilayer perceptron (MLP), a type of artificial neural network. It also encompasses the development of criteria to confidently make deductions about the training process and characteristics. The methodology called gradient descent looks to minimize errors in the modeled output in an iterative way. Additionally, we correlate the results to the learning problem that motivates the use of a MLP model. The work is based on non-standard data provided as part of our course, giving us a chance to put our theoretical knowledge into practice.

# Hybrid applications [![](https://img.shields.io/badge/pdf-EF3939?style=flat&logo=adobeacrobatreader&logoColor=white)](https://github.com/asgutierrt/Introduction-to-IA/blob/b1d1d0993b36306062f5e61831ed4cfebb4f4854/convolutional_networks/on_autoencoder_cnn_gan_training.pdf)
## Autoencoders and Convolutional Neural Networks (LeNet5)
## Generative adversarial networks and style transfer
